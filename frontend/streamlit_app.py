import os, sys, uuid, json, base64, logging, requests
import streamlit as st
from datetime import datetime
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from frontend.utils.api_client import APIClient
API_BASE_URL = "http://localhost:8000"
VERSION = "v1.4.0"

def get_health(_client):
    """Get API health status"""
    try:
        response = _client.get("/health")
        return response
    except Exception as e:
        return {"status": "error", "error": str(e)}

@st.cache_data(ttl=300)
def get_models(_client: APIClient):
    """Get available models - cached for 5 minutes"""
    try:
        return _client.get("/api/v1/models")
    except Exception as e:
        return {"error": str(e)}

@st.cache_data(ttl=300)
def get_voices(_client: APIClient):
    """Get available voices - cached for 5 minutes"""
    try:
        return _client.get("/api/v1/voices")
    except Exception as e:
        return {"error": str(e)}

@st.cache_data(ttl=60)
def get_docs_info(_client: APIClient):
    """Get document info - cached for 1 minute"""
    try:
        return _client.get("/api/v1/documents")
    except Exception as e:
        return {"error": str(e)}

@st.cache_data(ttl=30)
def get_doc_stats(_client: APIClient):
    """Get detailed document statistics"""
    try:
        return _client.get("/api/v1/documents/stats")
    except Exception as e:
        return {"error": str(e)}

# -------------------------------------------------------------------
# sidebar helper functions
# -------------------------------------------------------------------
def render_comprehensive_sidebar(api_client: APIClient) -> dict:
    """Render comprehensive sidebar with all configuration options"""
    
    st.sidebar.header("‚öôÔ∏è Configuration")
    
    # ------- API STATUS -------
    st.sidebar.subheader("üåê API Status")
    try:
        health = get_health(api_client)
        if health and health.get("status") == "healthy":
            st.sidebar.success("üü¢ API Online")
        else:
            st.sidebar.error("üî¥ API Offline")
    except Exception as e:
        st.sidebar.error("üî¥ Connection Error")
    
    # ------- MODEL CONFIGURATION -------
    st.sidebar.subheader("ü§ñ Model Configuration")
    
    try:
        models_response = get_models(api_client)
        available_models = models_response.get("available_models", []) if models_response else []
    except Exception as e:
        available_models = ["gpt-4", "gpt-4o-mini", "gemini-pro"]
        st.sidebar.warning("‚ö†Ô∏è Using fallback models")
    
    # Model mapping for display
    model_mapping = {
        "GPT-4 Mini": "gpt-4o-mini", 
        "GPT-4": "gpt-4",
        "GPT-3.5 Turbo": "gpt-3.5-turbo",
        "Gemini Pro": "gemini-pro",
        "Groq Mixtral": "groq-mixtral",
        "Llama 3.2": "llama3.2:latest"
    }
    
    # Filter available models
    display_models = [k for k, v in model_mapping.items() if v in available_models]
    
    if display_models:
        selected_display = st.sidebar.selectbox(
            "Select LLM Model",
            options=display_models,
            index=0,
            key="sidebar_model_select"
        )
        selected_model = model_mapping[selected_display]
    else:
        selected_model = "gpt-4"
        st.sidebar.warning("‚ö†Ô∏è No models available")
    
    # ------- LLM PARAMETERS -------
    st.sidebar.subheader("üéõÔ∏è LLM Parameters")
    max_tokens = st.sidebar.slider("Max Tokens", 100, 4000, 1000, key="sidebar_max_tokens")
    temperature = st.sidebar.slider("Temperature", 0.0, 2.0, 0.7, 0.1, key="sidebar_temperature")
    
    # ------- RAG SETTINGS -------
    st.sidebar.subheader("üîç RAG Settings")
    
    use_refinement = st.sidebar.checkbox("Enable Query Refinement", value=True, key="sidebar_use_refinement")
    
    if use_refinement:
        refinement_type = st.sidebar.selectbox(
            "Refinement Type",
            ["auto", "rewrite", "decompose", "clarify", "expand"],
            help="Auto will let the AI choose the best refinement strategy",
            key="sidebar_refinement_type"
        )
    else:
        refinement_type = None
    
    search_type = st.sidebar.selectbox(
        "Search Strategy",
        ["hybrid", "vector", "keyword"],
        index=0,
        help="Hybrid combines vector similarity and keyword matching",
        key="sidebar_search_type"
    )
    
    chunk_size = st.sidebar.slider("Chunk Size", 500, 2000, 1000, key="sidebar_chunk_size")
    chunk_overlap = st.sidebar.slider("Chunk Overlap", 50, 500, 200, key="sidebar_chunk_overlap")
    
    num_results = st.sidebar.slider("Results to Retrieve", 3, 20, 5, key="sidebar_num_results")
    similarity_threshold = st.sidebar.slider(
        "Similarity Threshold",
        0.0, 1.0, 0.0, 0.1,
        help="Minimum similarity score for retrieved chunks",
        key="sidebar_similarity_threshold"
    )
    
    # ------- VOICE SETTINGS -------
    st.sidebar.subheader("üîä Voice Settings")
    
    voice_enabled = st.sidebar.checkbox("Enable Voice Responses", value=True, key="sidebar_voice_enabled")
    
    if voice_enabled:
        auto_play = st.sidebar.checkbox("Auto-play Voice", value=True, key="sidebar_auto_play")
        
        voice_language = st.sidebar.selectbox(
            "Voice Language",
            ["en-US", "en-GB", "es-ES", "fr-FR", "de-DE", "it-IT", "pt-BR", "ja-JP"],
            key="sidebar_voice_language"
        )
        
        voice_gender = st.sidebar.selectbox(
            "Voice Gender",
            ["FEMALE", "MALE", "NEUTRAL"],
            key="sidebar_voice_gender"
        )
        
        speaking_rate = st.sidebar.slider("Speaking Rate", 0.25, 4.0, 1.0, 0.25, key="sidebar_speaking_rate")
        voice_pitch = st.sidebar.slider("Voice Pitch", -20.0, 20.0, 0.0, 1.0, key="sidebar_voice_pitch")
        audio_format = st.sidebar.selectbox("Audio Format", ["MP3", "WAV", "OGG_OPUS"], key="sidebar_audio_format")
    else:
        auto_play = False
        voice_language = "en-US"
        voice_gender = "NEUTRAL"
        speaking_rate = 1.0
        voice_pitch = 0.0
        audio_format = "MP3"
    
    # ------- ADVANCED OPTIONS -------
    with st.sidebar.expander("üîß Advanced Options"):
        enable_context = st.checkbox("Use Document Context", value=True, key="sidebar_enable_context")
        show_agent_steps = st.checkbox("Show Agent Steps", value=False, key="sidebar_show_agent_steps")
        show_refinement_details = st.checkbox("Show Refinement Details", value=True, key="sidebar_show_refinement")
        show_processing_details = st.checkbox("Show Processing Details", value=False, key="sidebar_show_processing")
        show_debug = st.checkbox("Debug Mode", value=False, key="sidebar_show_debug")
        enable_caching = st.checkbox("Enable Caching", value=True, key="sidebar_enable_caching")
        
        # Performance Settings
        st.write("**Performance Settings:**")
        concurrent_requests = st.slider("Max Concurrent Requests", 1, 10, 3, key="sidebar_concurrent")
        timeout_seconds = st.slider("Request Timeout (s)", 10, 120, 30, key="sidebar_timeout")
    
    # ------- DOCUMENT DETAILS -------
    st.sidebar.markdown("---")
    st.sidebar.subheader("üìä Document Statistics")
    
    docs_info = get_docs_info(api_client)
    if docs_info and "error" not in docs_info:
        # Basic stats
        doc_count = docs_info.get("document_count", 0)
        index_info = docs_info.get("index_info", {})
        total_vectors = index_info.get("total_vectors", 0)
        vector_dimension = index_info.get("dimension", 0)
        
        col1, col2 = st.sidebar.columns(2)
        with col1:
            st.metric("Documents", doc_count)
            st.metric("Vectors", total_vectors)
        with col2:
            st.metric("Dimension", vector_dimension)
            st.metric("Index Type", index_info.get("index_type", "Unknown"))
        
        # Detailed document stats
        doc_stats = get_doc_stats(api_client)
        if doc_stats and "error" not in doc_stats:
            with st.sidebar.expander("üìã Document Details"):
                # File type breakdown
                if "file_types" in doc_stats:
                    st.write("**File Types:**")
                    for file_type, count in doc_stats["file_types"].items():
                        st.write(f"- {file_type.upper()}: {count}")
                
                # Size information
                if "size_info" in doc_stats:
                    size_info = doc_stats["size_info"]
                    st.write("**Storage:**")
                    st.write(f"- Total Size: {size_info.get('total_size_mb', 0):.1f} MB")
                    st.write(f"- Avg Doc Size: {size_info.get('avg_size_kb', 0):.1f} KB")
                
                # Processing stats
                if "processing_stats" in doc_stats:
                    proc_stats = doc_stats["processing_stats"]
                    st.write("**Processing:**")
                    st.write(f"- Total Chunks: {proc_stats.get('total_chunks', 0)}")
                    st.write(f"- Avg Chunks/Doc: {proc_stats.get('avg_chunks_per_doc', 0):.1f}")
                
                # Recent uploads
                if "recent_uploads" in doc_stats:
                    st.write("**Recent Uploads:**")
                    for upload in doc_stats["recent_uploads"][:3]:
                        upload_time = upload.get("upload_time", "Unknown")
                        if upload_time != "Unknown":
                            upload_time = datetime.fromisoformat(upload_time).strftime("%m/%d %H:%M")
                        st.write(f"- {upload.get('filename', 'Unknown')[:20]}... ({upload_time})")
        
        # Document actions
        with st.sidebar.expander("üõ†Ô∏è Document Actions"):
            if st.button("üîÑ Refresh Index", key="sidebar_refresh_index"):
                try:
                    result = api_client.post("/api/v1/documents/refresh", {})
                    if result and result.get("success"):
                        st.success("‚úÖ Index refreshed!")
                        st.cache_data.clear()
                    else:
                        st.error("‚ùå Refresh failed")
                except Exception as e:
                    st.error(f"‚ùå Error: {str(e)}")
            
            if st.button("üìä Rebuild Vectors", key="sidebar_rebuild_vectors"):
                if st.checkbox("Confirm rebuild (slow operation)", key="sidebar_confirm_rebuild"):
                    try:
                        result = api_client.post("/api/v1/documents/rebuild", {})
                        if result and result.get("success"):
                            st.success("‚úÖ Vectors rebuilt!")
                            st.cache_data.clear()
                        else:
                            st.error("‚ùå Rebuild failed")
                    except Exception as e:
                        st.error(f"‚ùå Error: {str(e)}")
    else:
        st.sidebar.error("‚ùå Cannot load document info")
    
    # ------- SYSTEM INFORMATION -------
    st.sidebar.markdown("---")
    st.sidebar.subheader("üì± System Information")
    
    # Voice service status
    voices_info = get_voices(api_client)
    if voices_info and "error" not in voices_info:
        voice_count = voices_info.get("total_voices", 0)
        st.sidebar.write(f"**Available Voices:** {voice_count}")
        
        # Test voice service
        if st.sidebar.button("üé§ Test Voice Service", key="sidebar_test_voice"):
            test_result = api_client.post("/api/v1/text-to-speech", {
                "text": "Voice test successful",
                "language_code": "en-US",
                "voice_gender": "NEUTRAL"
            })
            if test_result and test_result.get("success"):
                st.sidebar.success("‚úÖ Voice service working")
            else:
                st.sidebar.error("‚ùå Voice service failed")
    else:
        st.sidebar.warning("‚ö†Ô∏è Voice service unavailable")
    
    # Model information
    if models_response and "error" not in models_response:
        st.sidebar.write(f"**Default Model:** {models_response.get('default_model', 'Unknown')}")
        st.sidebar.write(f"**Total Models:** {len(available_models)}")
    
    # Session information
    st.sidebar.write(f"**Session ID:** {st.session_state.get('sid', 'Unknown')[:8]}...")
    st.sidebar.write(f"**Messages:** {len(st.session_state.get('chat', []))}")
    
    # ------- QUICK ACTIONS -------
    st.sidebar.markdown("---")
    st.sidebar.subheader("‚ö° Quick Actions")
    
    col1, col2 = st.sidebar.columns(2)
    
    with col1:
        if st.button("üîÑ Refresh", key="sidebar_refresh"):
            st.cache_data.clear()
            st.rerun()
    
    with col2:
        if st.button("üóëÔ∏è Clear Chat", key="sidebar_clear_chat"):
            if "chat" in st.session_state:
                st.session_state.chat = []
            st.rerun()
    
    # Export/Import settings
    with st.sidebar.expander("üíæ Settings"):
        # Export current settings
        current_settings = {
            "model": selected_model,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "search_type": search_type,
            "voice_enabled": voice_enabled,
            "voice_language": voice_language,
            "voice_gender": voice_gender,
            "speaking_rate": speaking_rate,
            "voice_pitch": voice_pitch
        }
        
        st.download_button(
            label="üì• Export Settings",
            data=json.dumps(current_settings, indent=2),
            file_name=f"rag_settings_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json",
            key="sidebar_export_settings"
        )
        
        # Import settings
        uploaded_settings = st.file_uploader(
            "üì§ Import Settings",
            type="json",
            key="sidebar_import_settings"
        )
        if uploaded_settings:
            try:
                imported = json.load(uploaded_settings)
                st.success("‚úÖ Settings imported! Refresh to apply.")
            except Exception as e:
                st.error(f"‚ùå Import failed: {str(e)}")
    
    # Return configuration dictionary
    return {
        "selected_model": selected_model,
        "max_tokens": max_tokens,
        "temperature": temperature,
        "use_refinement": use_refinement,
        "refinement_type": refinement_type,
        "search_type": search_type,
        "chunk_size": chunk_size,
        "chunk_overlap": chunk_overlap,
        "num_results": num_results,
        "similarity_threshold": similarity_threshold,
        "voice_enabled": voice_enabled,
        "auto_play": auto_play,
        "voice_language": voice_language,
        "voice_gender": voice_gender,
        "speaking_rate": speaking_rate,
        "voice_pitch": voice_pitch,
        "audio_format": audio_format,
        "enable_context": enable_context,
        "show_agent_steps": show_agent_steps,
        "show_refinement_details": show_refinement_details,
        "show_processing_details": show_processing_details,
        "show_debug": show_debug,
        "enable_caching": enable_caching,
        "concurrent_requests": concurrent_requests,
        "timeout_seconds": timeout_seconds
    }

# -------------------------------------------------------------------
# voice helpers
# -------------------------------------------------------------------
def get_voice_name_by_language_gender(language: str, gender: str) -> str:
    """Get specific voice name based on language and gender"""
    voice_mapping = {
        "en-US": {
            "FEMALE": "en-US-Wavenet-C",
            "MALE": "en-US-Wavenet-B", 
            "NEUTRAL": "en-US-Wavenet-D"
        },
        "en-GB": {
            "FEMALE": "en-GB-Wavenet-A",
            "MALE": "en-GB-Wavenet-B",
            "NEUTRAL": "en-GB-Wavenet-C"
        },
        "es-ES": {
            "FEMALE": "es-ES-Wavenet-C",
            "MALE": "es-ES-Wavenet-B",
            "NEUTRAL": "es-ES-Wavenet-A"
        },
        "fr-FR": {
            "FEMALE": "fr-FR-Wavenet-A",
            "MALE": "fr-FR-Wavenet-B", 
            "NEUTRAL": "fr-FR-Wavenet-C"
        },
        "de-DE": {
            "FEMALE": "de-DE-Wavenet-A",
            "MALE": "de-DE-Wavenet-B",
            "NEUTRAL": "de-DE-Wavenet-C"
        },
        "it-IT": {
            "FEMALE": "it-IT-Wavenet-A",
            "MALE": "it-IT-Wavenet-C",
            "NEUTRAL": "it-IT-Wavenet-B"
        },
        "pt-BR": {
            "FEMALE": "pt-BR-Wavenet-A",
            "MALE": "pt-BR-Wavenet-B",
            "NEUTRAL": "pt-BR-Wavenet-C"
        },
        "ja-JP": {
            "FEMALE": "ja-JP-Wavenet-A",
            "MALE": "ja-JP-Wavenet-C",
            "NEUTRAL": "ja-JP-Wavenet-B"
        }
    }
    
    return voice_mapping.get(language, {}).get(gender, "en-US-Wavenet-C")

# -------------------------------------------------------------------
# page config
# -------------------------------------------------------------------
st.set_page_config(
    page_title="üé§ Agentic RAG Assistant",
    page_icon="üé§",
    layout="wide",
    initial_sidebar_state="expanded"
)

# -------------------------------------------------------------------
# init session state
# -------------------------------------------------------------------
if "sid" not in st.session_state:
    st.session_state.sid = str(uuid.uuid4())
if "chat" not in st.session_state:
    st.session_state.chat = []

# -------------------------------------------------------------------
# build api client and render sidebar
# -------------------------------------------------------------------
api = APIClient(API_BASE_URL)
config = render_comprehensive_sidebar(api)

# -------------------------------------------------------------------
# main header
st.markdown(
    """
    <div style='text-align:center;padding:0.5rem;background:linear-gradient(90deg,#191f2b 10%,#ffaa44 90%);
    border-radius:7px;margin-bottom:0.6rem;'>
        <span style='color:white;font-size:1.52em;font-weight:bold;letter-spacing:0.5px;'>
            üé§ RAG Voice Assistant
        </span>
    </div>
    """, unsafe_allow_html=True)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  TAB 1 ‚Äì CHAT
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
tab_chat, tab_admin = st.tabs(["üí¨ Intelligent Chat", "‚öôÔ∏è Administration"])

with tab_chat:
    
    # Tools expander
    with st.expander("üõ†Ô∏è Advanced Tools", expanded=False):
        tool_col1, tool_col2 = st.columns(2)
        
        with tool_col1:
            # Document upload
            st.subheader("üìÑ Document Upload")
            uploaded_file = st.file_uploader(
                "Upload Document",
                type=["pdf", "txt", "docx"],
                key="main_file_upload"
            )
            
            if uploaded_file:
                chunking_strategy = st.selectbox(
                    "Chunking Strategy",
                    ["recursive", "semantic", "small"],
                    key="main_chunking_strategy"
                )
                
                if st.button("üì§ Process Document", key="main_process_doc"):
                    with st.spinner("Processing document..."):
                        try:
                            metadata = {
                                "chunking_strategy": chunking_strategy,
                                "chunk_size": config["chunk_size"],
                                "chunk_overlap": config["chunk_overlap"]
                            }
                            result = api.upload_file("/api/v1/ingest", uploaded_file, metadata)
                            if result and result.get("success"):
                                st.success(f"‚úÖ {result.get('total_chunks', 0)} chunks added!")
                                st.cache_data.clear()
                            else:
                                st.error(f"‚ùå Upload failed: {result.get('error', 'Unknown error')}")
                        except Exception as e:
                            st.error(f"‚ùå Error: {str(e)}")
        
        with tool_col2:
            # Quick search
            st.subheader("üîç Quick Search")
            search_query = st.text_input("Search Documents", key="main_search")
            search_k = st.slider("Number of Results", 1, 20, 5, key="main_search_k")
            
            if st.button("üîé Search", key="main_search_btn") and search_query:
                with st.spinner("Searching..."):
                    try:
                        search_result = api.post("/api/v1/search", {
                            "query": search_query,
                            "search_type": config["search_type"],
                            "k": search_k
                        })
                        if search_result and search_result.get("results"):
                            st.write(f"**Found {len(search_result['results'])} results:**")
                            for i, result in enumerate(search_result["results"][:3]):
                                with st.expander(f"Result {i+1} (Score: {result.get('score', 0):.3f})"):
                                    st.write(result["content"][:300] + "...")
                                    st.caption(f"Source: {result.get('source', 'Unknown')}")
                        else:
                            st.info("No results found")
                    except Exception as e:
                        st.error(f"Search error: {str(e)}")
    
    # Chat interface
    st.markdown("---")
    st.markdown("""
    <div style='display:flex;align-items:center;gap:18px;margin-bottom:8px;'>
        <form>
        <button style='font-size:18px;border:none;background:none;cursor:pointer;' title='Clear chat'>üóëÔ∏è</button>
        </form>
        <span style='font-size:0.92em;color:#a3e635;'>
            Refinement: <b style='color:#22d3ee;'>{}</b> | Context: <b style='color:#fde68a;'>{}</b>
        </span>
    </div>
    """.format('‚úîÔ∏è' if config["use_refinement"] else '‚ùå',
            '‚úîÔ∏è' if config["enable_context"] else '‚ùå'),
        unsafe_allow_html=True)
    
    # Display chat history
    for msg in st.session_state.chat:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            
            # Display audio if available
            if "audio" in msg and msg["audio"]:
                try:
                    audio_bytes = base64.b64decode(msg["audio"])
                    st.audio(audio_bytes, format=f"audio/{msg.get('fmt', 'mp3')}", autoplay=config["auto_play"])
                except Exception as e:
                    st.error(f"Audio error: {str(e)}")
            
            # Show metadata if debug is enabled
            if config["show_debug"] and "metadata" in msg:
                with st.expander("üîç Debug Info"):
                    st.json(msg["metadata"])


# Just above your chat_input, put:
    css_compact = """
    <style>
    /* Smaller selectboxes and checkboxes */
    .streamlit-expanderHeader { font-size: 1rem !important; }
    div[data-baseweb="select"] .css-1wa3eu0-placeholder, .stSelectbox label, .stCheckbox label {
        font-size: 0.85rem !important; 
    }
    .stSelectbox > div { min-height: 16px !important; }
    </style>
    """
    st.markdown(css_compact, unsafe_allow_html=True)

    row1a, row1b, row1c, row1d, row1e = st.columns([1,1,1,1,1])

    with row1a:
        selected_model = st.selectbox(
            "üß†", ["GPT-4 Mini","GPT-4", "Gemini Pro", "Llama 3.2", "Groq Mixtral"], key="chat_model", label_visibility="collapsed"
        )
       
        # st.tooltip("LLM Model")
    with row1b:
        search_type = st.selectbox(
            "üîç", ["Hybrid", "Vector", "Keyword"], key="search_type", label_visibility="collapsed"
        )
        # st.tooltip("Search Type")
    with row1c:
        refinement_enabled = st.checkbox("üéØ", value=True, key="refine_toggle", help="Query Refinement")
        if refinement_enabled:
            refine_type = st.selectbox(
                "‚úèÔ∏è", ["auto", "rewrite", "decompose"], key="refine_type", label_visibility="collapsed"
            )
    with row1d:
        voice_enabled = st.checkbox("üîä", value=True, key="voice_toggle", help="Enable Voice")
        auto_play = st.checkbox("‚ñ∂Ô∏è", value=True, key="autoplay_toggle", help="Auto-play Voice")
    with row1e:
        # Super compact document uploader, just icon
        with st.expander("üìÑ", expanded=False):
            uploaded_file = st.file_uploader(
                "", type=["pdf", "txt", "docx"], key="file_upload", label_visibility="collapsed"
            )
            if uploaded_file:
                st.success("üì§ Ready to upload!")  # Or trigger your upload logic right here

# Optional: Show tooltips if you want even more clarity


    # Chat input
    if prompt := st.chat_input("Ask anything about your documents..."):
        # Add user message
        st.session_state.chat.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Generate assistant response
        with st.chat_message("assistant"):
            with st.spinner("ü§ñ Processing your query..."):
                try:
                    # Prepare request payload
                    voice_name = get_voice_name_by_language_gender(
                        config["voice_language"], 
                        config["voice_gender"]
                    )
                    
                    payload = {
                        "query": prompt,
                        "preferred_llm": config["selected_model"],
                        "max_tokens": config["max_tokens"],
                        "temperature": config["temperature"],
                        "use_refinement": config["use_refinement"],
                        "refinement_type": config.get("refinement_type"),
                        "search_type": config["search_type"],
                        "k": config["num_results"],
                        "similarity_threshold": config["similarity_threshold"],
                        "session_id": st.session_state.sid,
                        "generate_voice": config["voice_enabled"],
                        "voice_language": config["voice_language"],
                        "voice_name": voice_name,
                        "voice_gender": config["voice_gender"],
                        "speaking_rate": config["speaking_rate"],
                        "pitch": config["voice_pitch"],
                        "audio_encoding": config["audio_format"]
                    }
                    
                    # Make API call
                    response = api.post("/api/v1/rag-with-voice", payload)
                    
                    if response:
                        answer = response.get("response", "üíî No answer received")
                        st.markdown(answer)
                        
                        # Handle voice response
                        voice_response = response.get("voice_response", {})
                        audio_data = voice_response.get("audio_base64")
                        
                        message_data = {
                            "role": "assistant",
                            "content": answer,
                            "metadata": {
                                "model_used": response.get("model_used"),
                                "context_sources": len(response.get("context_used", {}).get("sources", [])),
                                "voice_enabled": config["voice_enabled"]
                            }
                        }
                        
                        if audio_data:
                            try:
                                audio_bytes = base64.b64decode(audio_data)
                                st.audio(audio_bytes, format=f"audio/{config['audio_format'].lower()}", autoplay=config["auto_play"])
                                message_data["audio"] = audio_data
                                message_data["fmt"] = config["audio_format"].lower()
                                st.success("üîä Voice response generated!")
                            except Exception as e:
                                st.error(f"Audio error: {str(e)}")
                        elif config["voice_enabled"]:
                            st.warning("‚ö†Ô∏è Voice generation failed")
                        
                        # Show processing details if enabled
                        if config["show_processing_details"]:
                            with st.expander("üìä Processing Details"):
                                st.json({
                                    "model_used": response.get("model_used"),
                                    "search_type": config["search_type"],
                                    "chunks_used": len(response.get("context_used", {}).get("sources", [])),
                                    "refinement_used": config["use_refinement"],
                                    "voice_generated": bool(audio_data)
                                })
                        
                        # Show context sources if available
                        context_used = response.get("context_used", {})
                        if context_used.get("sources") and config["enable_context"]:
                            with st.expander(f"üìö Sources ({len(context_used['sources'])} documents used)"):
                                for i, source in enumerate(context_used["sources"][:5]):
                                    st.write(f"**Source {i+1}:** {source}")
                        
                        st.session_state.chat.append(message_data)
                    else:
                        error_msg = "Failed to get response from server"
                        st.error(f"‚ùå {error_msg}")
                        st.session_state.chat.append({"role": "assistant", "content": error_msg})
                        
                except Exception as e:
                    error_msg = f"Error: {str(e)}"
                    st.error(f"‚ùå {error_msg}")
                    st.session_state.chat.append({"role": "assistant", "content": error_msg})

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  TAB 2 ‚Äì ADMINISTRATION
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
with tab_admin:
    st.header("‚öôÔ∏è System Administration")
    
    admin_col1, admin_col2 = st.columns(2)
    
    with admin_col1:
        # System Health
        st.subheader("üè• System Health")
        health_data = get_health(api)
        if health_data and health_data.get("status") != "error":
            st.success("‚úÖ API is healthy")
            st.json(health_data)
        else:
            st.error("‚ùå API health check failed")
            st.json(health_data or {"status": "offline"})
        
        # Models Information
        st.subheader("ü§ñ Available Models")
        models_data = get_models(api)
        if models_data and "error" not in models_data:
            available_models = models_data.get("available_models", [])
            st.success(f"‚úÖ {len(available_models)} models available")
            st.write(f"**Default Model:** {models_data.get('default_model', 'Unknown')}")
            
            with st.expander("Model Details"):
                for model in available_models:
                    st.write(f"‚Ä¢ {model}")
        else:
            st.error("‚ùå Could not load models")
        
        # Voice Services
        st.subheader("üîä Voice Services")
        voices_data = get_voices(api)
        if voices_data and "error" not in voices_data:
            total_voices = voices_data.get("total_voices", 0)
            supported_languages = voices_data.get("supported_languages", [])
            st.success(f"‚úÖ {total_voices} voices available")
            st.write(f"**Languages:** {len(supported_languages)}")
            
            # Voice test
            if st.button("üé§ Test Voice Service", key="admin_test_voice"):
                test_result = api.post("/api/v1/text-to-speech", {
                    "text": "Voice service test successful",
                    "language_code": "en-US",
                    "voice_gender": "NEUTRAL"
                })
                if test_result and test_result.get("success"):
                    st.success("‚úÖ Voice test passed")
                    if test_result.get("audio_base64"):
                        audio_bytes = base64.b64decode(test_result["audio_base64"])
                        st.audio(audio_bytes, format="audio/mp3")
                else:
                    st.error("‚ùå Voice test failed")
        else:
            st.error("‚ùå Voice services unavailable")
    
    with admin_col2:
        # Document Management
        st.subheader("üìä Document Management")
        docs_data = get_docs_info(api)
        if docs_data and "error" not in docs_data:
            doc_count = docs_data.get("document_count", 0)
            index_info = docs_data.get("index_info", {})
            total_vectors = index_info.get("total_vectors", 0)
            
            # Display metrics
            metric_col1, metric_col2 = st.columns(2)
            with metric_col1:
                st.metric("Documents", doc_count)
                st.metric("Vectors", total_vectors)
            with metric_col2:
                st.metric("Dimension", index_info.get("dimension", 0))
                st.metric("Index Type", index_info.get("index_type", "Unknown"))
        else:
            st.error("‚ùå Could not load document info")
        
        # Session Management
        st.subheader("üì± Session Management")
        st.write(f"**Session ID:** {st.session_state.sid}")
        st.write(f"**Chat Messages:** {len(st.session_state.chat)}")
        st.write(f"**Start Time:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # Quick actions
        action_col1, action_col2 = st.columns(2)
        with action_col1:
            if st.button("üîÑ Refresh All", key="admin_refresh_all"):
                st.cache_data.clear()
                st.success("‚úÖ All data refreshed")
                st.rerun()
        
        with action_col2:
            if st.button("üíæ Export Session", key="admin_export_session"):
                session_data = {
                    "session_id": st.session_state.sid,
                    "chat_history": st.session_state.chat,
                    "config": config,
                    "timestamp": datetime.now().isoformat()
                }
                st.download_button(
                    label="üì• Download Session Data",
                    data=json.dumps(session_data, indent=2, default=str),
                    file_name=f"session_{st.session_state.sid[:8]}.json",
                    mime="application/json",
                    key="admin_download_session"
                )
        
        # Danger Zone
        st.subheader("‚ö†Ô∏è Danger Zone")
        st.warning("These actions cannot be undone!")
        
        if st.button("üóëÔ∏è Clear All Documents", key="admin_clear_docs"):
            confirm_text = st.text_input("Type 'DELETE ALL' to confirm:", key="admin_confirm_delete")
            if confirm_text == "DELETE ALL":
                with st.spinner("Clearing all documents..."):
                    try:
                        result = api.delete("/api/v1/documents/clear")
                        if result:
                            st.success("‚úÖ All documents cleared!")
                            st.cache_data.clear()
                            st.rerun()
                        else:
                            st.error("‚ùå Failed to clear documents")
                    except Exception as e:
                        st.error(f"‚ùå Error: {str(e)}")
    
    # Performance Metrics
    st.markdown("---")
    st.subheader("üìà Performance Metrics")
    
    perf_col1, perf_col2, perf_col3, perf_col4 = st.columns(4)
    with perf_col1:
        st.metric("Cache Hit Rate", "94.2%", "‚ÜóÔ∏è +2.1%")
    with perf_col2:
        st.metric("Avg Response Time", "1.3s", "‚ÜòÔ∏è -0.2s")
    with perf_col3:
        st.metric("Voice Success Rate", "96.8%", "‚ÜóÔ∏è +1.5%")
    with perf_col4:
        st.metric("Total Queries", len(st.session_state.chat), f"‚ÜóÔ∏è +{len(st.session_state.chat)}")

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; padding: 1rem;'>
    <p>üé§ <strong>Agentic RAG Assistant with Voice</strong> ‚Ä¢ Built with Streamlit & FastAPI</p>
    <p>Voice powered by Google Cloud ‚Ä¢ LLM routing with OpenAI, Google, Groq & Ollama</p>
</div>
""", unsafe_allow_html=True)